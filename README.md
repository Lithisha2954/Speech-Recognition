# Speech-Recognition
This project implements a deep learning-based speech command recognition system using TensorFlow and the Mini Speech Commands dataset. It is designed to classify short spoken words such as “yes”, “no”, and “stop”. The audio data is preprocessed by converting waveforms into spectrograms using Short-Time Fourier Transform (STFT), which are then fed into a custom Convolutional Neural Network (CNN) consisting of Conv2D, MaxPooling, Dropout, and Dense layers. The model is trained for 15 epochs with early stopping to prevent overfitting, and performance is visualized using loss and accuracy plots. Real-time testing is enabled by converting user-recorded audio files from .m4a to .wav, allowing predictions using the trained model. Finally, the model is saved in Keras’s native .keras format for deployment and reuse. This project showcases the application of deep learning in real-time voice command recognition.
